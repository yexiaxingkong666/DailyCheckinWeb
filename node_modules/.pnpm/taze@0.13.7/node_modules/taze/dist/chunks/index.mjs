import { v as valid_1, n as getDefaultExportFromCjs } from '../shared/taze.c2ef066c.mjs';
import require$$0 from 'path';
import require$$0$2 from 'url';
import require$$0$1 from 'stream';
import require$$0$3 from 'os';
import path$1 from 'node:path';
import os$1 from 'node:os';
import require$$0$5 from 'fs/promises';
import require$$0$4 from 'node:url';
import { r as requireCommonjs, a as requireCommonjs$1 } from '../shared/taze.4417d9db.mjs';

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var cjs = {};

Object.defineProperty(cjs, "__esModule", { value: true });
cjs.walkUp = void 0;
const path_1 = require$$0;
const walkUp$1 = function* (path) {
    for (path = (0, path_1.resolve)(path); path;) {
        yield path;
        const pp = (0, path_1.dirname)(path);
        if (pp === path) {
            break;
        }
        else {
            path = pp;
        }
    }
};
cjs.walkUp = walkUp$1;

const { hasOwnProperty: hasOwnProperty$1 } = Object.prototype;

const encode = (obj, opt = {}) => {
  if (typeof opt === 'string') {
    opt = { section: opt };
  }
  opt.align = opt.align === true;
  opt.newline = opt.newline === true;
  opt.sort = opt.sort === true;
  opt.whitespace = opt.whitespace === true || opt.align === true;
  // The `typeof` check is required because accessing the `process` directly fails on browsers.
  /* istanbul ignore next */
  opt.platform = opt.platform || (typeof process !== 'undefined' && process.platform);
  opt.bracketedArray = opt.bracketedArray !== false;

  /* istanbul ignore next */
  const eol = opt.platform === 'win32' ? '\r\n' : '\n';
  const separator = opt.whitespace ? ' = ' : '=';
  const children = [];

  const keys = opt.sort ? Object.keys(obj).sort() : Object.keys(obj);

  let padToChars = 0;
  // If aligning on the separator, then padToChars is determined as follows:
  // 1. Get the keys
  // 2. Exclude keys pointing to objects unless the value is null or an array
  // 3. Add `[]` to array keys
  // 4. Ensure non empty set of keys
  // 5. Reduce the set to the longest `safe` key
  // 6. Get the `safe` length
  if (opt.align) {
    padToChars = safe(
      (
        keys
          .filter(k => obj[k] === null || Array.isArray(obj[k]) || typeof obj[k] !== 'object')
          .map(k => Array.isArray(obj[k]) ? `${k}[]` : k)
      )
        .concat([''])
        .reduce((a, b) => safe(a).length >= safe(b).length ? a : b)
    ).length;
  }

  let out = '';
  const arraySuffix = opt.bracketedArray ? '[]' : '';

  for (const k of keys) {
    const val = obj[k];
    if (val && Array.isArray(val)) {
      for (const item of val) {
        out += safe(`${k}${arraySuffix}`).padEnd(padToChars, ' ') + separator + safe(item) + eol;
      }
    } else if (val && typeof val === 'object') {
      children.push(k);
    } else {
      out += safe(k).padEnd(padToChars, ' ') + separator + safe(val) + eol;
    }
  }

  if (opt.section && out.length) {
    out = '[' + safe(opt.section) + ']' + (opt.newline ? eol + eol : eol) + out;
  }

  for (const k of children) {
    const nk = splitSections(k, '.').join('\\.');
    const section = (opt.section ? opt.section + '.' : '') + nk;
    const child = encode(obj[k], {
      ...opt,
      section,
    });
    if (out.length && child.length) {
      out += eol;
    }

    out += child;
  }

  return out
};

function splitSections (str, separator) {
  var lastMatchIndex = 0;
  var lastSeparatorIndex = 0;
  var nextIndex = 0;
  var sections = [];

  do {
    nextIndex = str.indexOf(separator, lastMatchIndex);

    if (nextIndex !== -1) {
      lastMatchIndex = nextIndex + separator.length;

      if (nextIndex > 0 && str[nextIndex - 1] === '\\') {
        continue
      }

      sections.push(str.slice(lastSeparatorIndex, nextIndex));
      lastSeparatorIndex = nextIndex + separator.length;
    }
  } while (nextIndex !== -1)

  sections.push(str.slice(lastSeparatorIndex));

  return sections
}

const decode = (str, opt = {}) => {
  opt.bracketedArray = opt.bracketedArray !== false;
  const out = Object.create(null);
  let p = out;
  let section = null;
  //          section          |key      = value
  const re = /^\[([^\]]*)\]\s*$|^([^=]+)(=(.*))?$/i;
  const lines = str.split(/[\r\n]+/g);
  const duplicates = {};

  for (const line of lines) {
    if (!line || line.match(/^\s*[;#]/) || line.match(/^\s*$/)) {
      continue
    }
    const match = line.match(re);
    if (!match) {
      continue
    }
    if (match[1] !== undefined) {
      section = unsafe(match[1]);
      if (section === '__proto__') {
        // not allowed
        // keep parsing the section, but don't attach it.
        p = Object.create(null);
        continue
      }
      p = out[section] = out[section] || Object.create(null);
      continue
    }
    const keyRaw = unsafe(match[2]);
    let isArray;
    if (opt.bracketedArray) {
      isArray = keyRaw.length > 2 && keyRaw.slice(-2) === '[]';
    } else {
      duplicates[keyRaw] = (duplicates?.[keyRaw] || 0) + 1;
      isArray = duplicates[keyRaw] > 1;
    }
    const key = isArray ? keyRaw.slice(0, -2) : keyRaw;
    if (key === '__proto__') {
      continue
    }
    const valueRaw = match[3] ? unsafe(match[4]) : true;
    const value = valueRaw === 'true' ||
      valueRaw === 'false' ||
      valueRaw === 'null' ? JSON.parse(valueRaw)
      : valueRaw;

    // Convert keys with '[]' suffix to an array
    if (isArray) {
      if (!hasOwnProperty$1.call(p, key)) {
        p[key] = [];
      } else if (!Array.isArray(p[key])) {
        p[key] = [p[key]];
      }
    }

    // safeguard against resetting a previously defined
    // array by accidentally forgetting the brackets
    if (Array.isArray(p[key])) {
      p[key].push(value);
    } else {
      p[key] = value;
    }
  }

  // {a:{y:1},"a.b":{x:2}} --> {a:{y:1,b:{x:2}}}
  // use a filter to return the keys that have to be deleted.
  const remove = [];
  for (const k of Object.keys(out)) {
    if (!hasOwnProperty$1.call(out, k) ||
      typeof out[k] !== 'object' ||
      Array.isArray(out[k])) {
      continue
    }

    // see if the parent section is also an object.
    // if so, add it to that, and mark this one for deletion
    const parts = splitSections(k, '.');
    p = out;
    const l = parts.pop();
    const nl = l.replace(/\\\./g, '.');
    for (const part of parts) {
      if (part === '__proto__') {
        continue
      }
      if (!hasOwnProperty$1.call(p, part) || typeof p[part] !== 'object') {
        p[part] = Object.create(null);
      }
      p = p[part];
    }
    if (p === out && nl === l) {
      continue
    }

    p[nl] = out[k];
    remove.push(k);
  }
  for (const del of remove) {
    delete out[del];
  }

  return out
};

const isQuoted = val => {
  return (val.startsWith('"') && val.endsWith('"')) ||
    (val.startsWith("'") && val.endsWith("'"))
};

const safe = val => {
  if (
    typeof val !== 'string' ||
    val.match(/[=\r\n]/) ||
    val.match(/^\[/) ||
    (val.length > 1 && isQuoted(val)) ||
    val !== val.trim()
  ) {
    return JSON.stringify(val)
  }
  return val.split(';').join('\\;').split('#').join('\\#')
};

const unsafe = val => {
  val = (val || '').trim();
  if (isQuoted(val)) {
    // remove the single quotes before calling JSON.parse
    if (val.charAt(0) === "'") {
      val = val.slice(1, -1);
    }
    try {
      val = JSON.parse(val);
    } catch {
      // ignore errors
    }
  } else {
    // walk the val to find the first not-escaped ; character
    let esc = false;
    let unesc = '';
    for (let i = 0, l = val.length; i < l; i++) {
      const c = val.charAt(i);
      if (esc) {
        if ('\\;#'.indexOf(c) !== -1) {
          unesc += c;
        } else {
          unesc += '\\' + c;
        }

        esc = false;
      } else if (';#'.indexOf(c) !== -1) {
        break
      } else if (c === '\\') {
        esc = true;
      } else {
        unesc += c;
      }
    }
    if (esc) {
      unesc += '\\';
    }

    return unesc.trim()
  }
  return val
};

var ini$1 = {
  parse: decode,
  decode,
  stringify: encode,
  encode,
  safe,
  unsafe,
};

var nopt$2 = {exports: {}};

var lib$7 = abbrev$1;

function abbrev$1 (...args) {
  let list = args.length === 1 || Array.isArray(args[0]) ? args[0] : args;

  for (let i = 0, l = list.length; i < l; i++) {
    list[i] = typeof list[i] === 'string' ? list[i] : String(list[i]);
  }

  // sort them lexicographically, so that they're next to their nearest kin
  list = list.sort(lexSort);

  // walk through each, seeing how much it has in common with the next and previous
  const abbrevs = {};
  let prev = '';
  for (let ii = 0, ll = list.length; ii < ll; ii++) {
    const current = list[ii];
    const next = list[ii + 1] || '';
    let nextMatches = true;
    let prevMatches = true;
    if (current === next) {
      continue
    }
    let j = 0;
    const cl = current.length;
    for (; j < cl; j++) {
      const curChar = current.charAt(j);
      nextMatches = nextMatches && curChar === next.charAt(j);
      prevMatches = prevMatches && curChar === prev.charAt(j);
      if (!nextMatches && !prevMatches) {
        j++;
        break
      }
    }
    prev = current;
    if (j === cl) {
      abbrevs[current] = current;
      continue
    }
    for (let a = current.slice(0, j); j <= cl; j++) {
      abbrevs[a] = current;
      a += current.charAt(j);
    }
  }
  return abbrevs
}

function lexSort (a, b) {
  return a === b ? 0 : a > b ? 1 : -1
}

/* istanbul ignore next */

var debug$2 = process.env.DEBUG_NOPT || process.env.NOPT_DEBUG
  ? (...a) => console.error(...a)
  : () => {};

const url = require$$0$2;
const path = require$$0;
const Stream = require$$0$1.Stream;
const os = require$$0$3;
const debug$1 = debug$2;

function validateString (data, k, val) {
  data[k] = String(val);
}

function validatePath (data, k, val) {
  if (val === true) {
    return false
  }
  if (val === null) {
    return true
  }

  val = String(val);

  const isWin = process.platform === 'win32';
  const homePattern = isWin ? /^~(\/|\\)/ : /^~\//;
  const home = os.homedir();

  if (home && val.match(homePattern)) {
    data[k] = path.resolve(home, val.slice(2));
  } else {
    data[k] = path.resolve(val);
  }
  return true
}

function validateNumber (data, k, val) {
  debug$1('validate Number %j %j %j', k, val, isNaN(val));
  if (isNaN(val)) {
    return false
  }
  data[k] = +val;
}

function validateDate (data, k, val) {
  const s = Date.parse(val);
  debug$1('validate Date %j %j %j', k, val, s);
  if (isNaN(s)) {
    return false
  }
  data[k] = new Date(val);
}

function validateBoolean (data, k, val) {
  if (typeof val === 'string') {
    if (!isNaN(val)) {
      val = !!(+val);
    } else if (val === 'null' || val === 'false') {
      val = false;
    } else {
      val = true;
    }
  } else {
    val = !!val;
  }
  data[k] = val;
}

function validateUrl (data, k, val) {
  // Changing this would be a breaking change in the npm cli
  /* eslint-disable-next-line node/no-deprecated-api */
  val = url.parse(String(val));
  if (!val.host) {
    return false
  }
  data[k] = val.href;
}

function validateStream (data, k, val) {
  if (!(val instanceof Stream)) {
    return false
  }
  data[k] = val;
}

var typeDefs$3 = {
  String: { type: String, validate: validateString },
  Boolean: { type: Boolean, validate: validateBoolean },
  url: { type: url, validate: validateUrl },
  Number: { type: Number, validate: validateNumber },
  path: { type: path, validate: validatePath },
  Stream: { type: Stream, validate: validateStream },
  Date: { type: Date, validate: validateDate },
  Array: { type: Array },
};

const abbrev = lib$7;
const debug = debug$2;
const defaultTypeDefs = typeDefs$3;

const hasOwn = (o, k) => Object.prototype.hasOwnProperty.call(o, k);

const getType = (k, { types, dynamicTypes }) => {
  let hasType = hasOwn(types, k);
  let type = types[k];
  if (!hasType && typeof dynamicTypes === 'function') {
    const matchedType = dynamicTypes(k);
    if (matchedType !== undefined) {
      type = matchedType;
      hasType = true;
    }
  }
  return [hasType, type]
};

const isTypeDef = (type, def) => def && type === def;
const hasTypeDef = (type, def) => def && type.indexOf(def) !== -1;
const doesNotHaveTypeDef = (type, def) => def && !hasTypeDef(type, def);

function nopt$1 (args, {
  types,
  shorthands,
  typeDefs,
  invalidHandler,
  typeDefault,
  dynamicTypes,
} = {}) {
  debug(types, shorthands, args, typeDefs);

  const data = {};
  const argv = {
    remain: [],
    cooked: args,
    original: args.slice(0),
  };

  parse$1(args, data, argv.remain, { typeDefs, types, dynamicTypes, shorthands });

  // now data is full
  clean(data, { types, dynamicTypes, typeDefs, invalidHandler, typeDefault });
  data.argv = argv;

  Object.defineProperty(data.argv, 'toString', {
    value: function () {
      return this.original.map(JSON.stringify).join(' ')
    },
    enumerable: false,
  });

  return data
}

function clean (data, {
  types = {},
  typeDefs = {},
  dynamicTypes,
  invalidHandler,
  typeDefault,
} = {}) {
  const StringType = typeDefs.String?.type;
  const NumberType = typeDefs.Number?.type;
  const ArrayType = typeDefs.Array?.type;
  const BooleanType = typeDefs.Boolean?.type;
  const DateType = typeDefs.Date?.type;

  const hasTypeDefault = typeof typeDefault !== 'undefined';
  if (!hasTypeDefault) {
    typeDefault = [false, true, null];
    if (StringType) {
      typeDefault.push(StringType);
    }
    if (ArrayType) {
      typeDefault.push(ArrayType);
    }
  }

  const remove = {};

  Object.keys(data).forEach((k) => {
    if (k === 'argv') {
      return
    }
    let val = data[k];
    debug('val=%j', val);
    const isArray = Array.isArray(val);
    let [hasType, rawType] = getType(k, { types, dynamicTypes });
    let type = rawType;
    if (!isArray) {
      val = [val];
    }
    if (!type) {
      type = typeDefault;
    }
    if (isTypeDef(type, ArrayType)) {
      type = typeDefault.concat(ArrayType);
    }
    if (!Array.isArray(type)) {
      type = [type];
    }

    debug('val=%j', val);
    debug('types=', type);
    val = val.map((v) => {
      // if it's an unknown value, then parse false/true/null/numbers/dates
      if (typeof v === 'string') {
        debug('string %j', v);
        v = v.trim();
        if ((v === 'null' && ~type.indexOf(null))
            || (v === 'true' &&
               (~type.indexOf(true) || hasTypeDef(type, BooleanType)))
            || (v === 'false' &&
               (~type.indexOf(false) || hasTypeDef(type, BooleanType)))) {
          v = JSON.parse(v);
          debug('jsonable %j', v);
        } else if (hasTypeDef(type, NumberType) && !isNaN(v)) {
          debug('convert to number', v);
          v = +v;
        } else if (hasTypeDef(type, DateType) && !isNaN(Date.parse(v))) {
          debug('convert to date', v);
          v = new Date(v);
        }
      }

      if (!hasType) {
        if (!hasTypeDefault) {
          return v
        }
        // if the default type has been passed in then we want to validate the
        // unknown data key instead of bailing out earlier. we also set the raw
        // type which is passed to the invalid handler so that it can be
        // determined if during validation if it is unknown vs invalid
        rawType = typeDefault;
      }

      // allow `--no-blah` to set 'blah' to null if null is allowed
      if (v === false && ~type.indexOf(null) &&
          !(~type.indexOf(false) || hasTypeDef(type, BooleanType))) {
        v = null;
      }

      const d = {};
      d[k] = v;
      debug('prevalidated val', d, v, rawType);
      if (!validate$1(d, k, v, rawType, { typeDefs })) {
        if (invalidHandler) {
          invalidHandler(k, v, rawType, data);
        } else if (invalidHandler !== false) {
          debug('invalid: ' + k + '=' + v, rawType);
        }
        return remove
      }
      debug('validated v', d, v, rawType);
      return d[k]
    }).filter((v) => v !== remove);

    // if we allow Array specifically, then an empty array is how we
    // express 'no value here', not null.  Allow it.
    if (!val.length && doesNotHaveTypeDef(type, ArrayType)) {
      debug('VAL HAS NO LENGTH, DELETE IT', val, k, type.indexOf(ArrayType));
      delete data[k];
    } else if (isArray) {
      debug(isArray, data[k], val);
      data[k] = val;
    } else {
      data[k] = val[0];
    }

    debug('k=%s val=%j', k, val, data[k]);
  });
}

function validate$1 (data, k, val, type, { typeDefs } = {}) {
  const ArrayType = typeDefs?.Array?.type;
  // arrays are lists of types.
  if (Array.isArray(type)) {
    for (let i = 0, l = type.length; i < l; i++) {
      if (isTypeDef(type[i], ArrayType)) {
        continue
      }
      if (validate$1(data, k, val, type[i], { typeDefs })) {
        return true
      }
    }
    delete data[k];
    return false
  }

  // an array of anything?
  if (isTypeDef(type, ArrayType)) {
    return true
  }

  // Original comment:
  // NaN is poisonous.  Means that something is not allowed.
  // New comment: Changing this to an isNaN check breaks a lot of tests.
  // Something is being assumed here that is not actually what happens in
  // practice.  Fixing it is outside the scope of getting linting to pass in
  // this repo. Leaving as-is for now.
  /* eslint-disable-next-line no-self-compare */
  if (type !== type) {
    debug('Poison NaN', k, val, type);
    delete data[k];
    return false
  }

  // explicit list of values
  if (val === type) {
    debug('Explicitly allowed %j', val);
    data[k] = val;
    return true
  }

  // now go through the list of typeDefs, validate against each one.
  let ok = false;
  const types = Object.keys(typeDefs);
  for (let i = 0, l = types.length; i < l; i++) {
    debug('test type %j %j %j', k, val, types[i]);
    const t = typeDefs[types[i]];
    if (t && (
      (type && type.name && t.type && t.type.name) ?
        (type.name === t.type.name) :
        (type === t.type)
    )) {
      const d = {};
      ok = t.validate(d, k, val) !== false;
      val = d[k];
      if (ok) {
        data[k] = val;
        break
      }
    }
  }
  debug('OK? %j (%j %j %j)', ok, k, val, types[types.length - 1]);

  if (!ok) {
    delete data[k];
  }
  return ok
}

function parse$1 (args, data, remain, {
  types = {},
  typeDefs = {},
  shorthands = {},
  dynamicTypes,
} = {}) {
  const StringType = typeDefs.String?.type;
  const NumberType = typeDefs.Number?.type;
  const ArrayType = typeDefs.Array?.type;
  const BooleanType = typeDefs.Boolean?.type;

  debug('parse', args, data, remain);

  const abbrevs = abbrev(Object.keys(types));
  debug('abbrevs=%j', abbrevs);
  const shortAbbr = abbrev(Object.keys(shorthands));

  for (let i = 0; i < args.length; i++) {
    let arg = args[i];
    debug('arg', arg);

    if (arg.match(/^-{2,}$/)) {
      // done with keys.
      // the rest are args.
      remain.push.apply(remain, args.slice(i + 1));
      args[i] = '--';
      break
    }
    let hadEq = false;
    if (arg.charAt(0) === '-' && arg.length > 1) {
      const at = arg.indexOf('=');
      if (at > -1) {
        hadEq = true;
        const v = arg.slice(at + 1);
        arg = arg.slice(0, at);
        args.splice(i, 1, arg, v);
      }

      // see if it's a shorthand
      // if so, splice and back up to re-parse it.
      const shRes = resolveShort(arg, shortAbbr, abbrevs, { shorthands });
      debug('arg=%j shRes=%j', arg, shRes);
      if (shRes) {
        args.splice.apply(args, [i, 1].concat(shRes));
        if (arg !== shRes[0]) {
          i--;
          continue
        }
      }
      arg = arg.replace(/^-+/, '');
      let no = null;
      while (arg.toLowerCase().indexOf('no-') === 0) {
        no = !no;
        arg = arg.slice(3);
      }

      if (abbrevs[arg]) {
        arg = abbrevs[arg];
      }

      let [hasType, argType] = getType(arg, { types, dynamicTypes });
      let isTypeArray = Array.isArray(argType);
      if (isTypeArray && argType.length === 1) {
        isTypeArray = false;
        argType = argType[0];
      }

      let isArray = isTypeDef(argType, ArrayType) ||
        isTypeArray && hasTypeDef(argType, ArrayType);

      // allow unknown things to be arrays if specified multiple times.
      if (!hasType && hasOwn(data, arg)) {
        if (!Array.isArray(data[arg])) {
          data[arg] = [data[arg]];
        }
        isArray = true;
      }

      let val;
      let la = args[i + 1];

      const isBool = typeof no === 'boolean' ||
        isTypeDef(argType, BooleanType) ||
        isTypeArray && hasTypeDef(argType, BooleanType) ||
        (typeof argType === 'undefined' && !hadEq) ||
        (la === 'false' &&
         (argType === null ||
          isTypeArray && ~argType.indexOf(null)));

      if (isBool) {
        // just set and move along
        val = !no;
        // however, also support --bool true or --bool false
        if (la === 'true' || la === 'false') {
          val = JSON.parse(la);
          la = null;
          if (no) {
            val = !val;
          }
          i++;
        }

        // also support "foo":[Boolean, "bar"] and "--foo bar"
        if (isTypeArray && la) {
          if (~argType.indexOf(la)) {
            // an explicit type
            val = la;
            i++;
          } else if (la === 'null' && ~argType.indexOf(null)) {
            // null allowed
            val = null;
            i++;
          } else if (!la.match(/^-{2,}[^-]/) &&
                      !isNaN(la) &&
                      hasTypeDef(argType, NumberType)) {
            // number
            val = +la;
            i++;
          } else if (!la.match(/^-[^-]/) && hasTypeDef(argType, StringType)) {
            // string
            val = la;
            i++;
          }
        }

        if (isArray) {
          (data[arg] = data[arg] || []).push(val);
        } else {
          data[arg] = val;
        }

        continue
      }

      if (isTypeDef(argType, StringType)) {
        if (la === undefined) {
          la = '';
        } else if (la.match(/^-{1,2}[^-]+/)) {
          la = '';
          i--;
        }
      }

      if (la && la.match(/^-{2,}$/)) {
        la = undefined;
        i--;
      }

      val = la === undefined ? true : la;
      if (isArray) {
        (data[arg] = data[arg] || []).push(val);
      } else {
        data[arg] = val;
      }

      i++;
      continue
    }
    remain.push(arg);
  }
}

const SINGLES = Symbol('singles');
const singleCharacters = (arg, shorthands) => {
  let singles = shorthands[SINGLES];
  if (!singles) {
    singles = Object.keys(shorthands).filter((s) => s.length === 1).reduce((l, r) => {
      l[r] = true;
      return l
    }, {});
    shorthands[SINGLES] = singles;
    debug('shorthand singles', singles);
  }
  const chrs = arg.split('').filter((c) => singles[c]);
  return chrs.join('') === arg ? chrs : null
};

function resolveShort (arg, ...rest) {
  const { types = {}, shorthands = {} } = rest.length ? rest.pop() : {};
  const shortAbbr = rest[0] ?? abbrev(Object.keys(shorthands));
  const abbrevs = rest[1] ?? abbrev(Object.keys(types));

  // handle single-char shorthands glommed together, like
  // npm ls -glp, but only if there is one dash, and only if
  // all of the chars are single-char shorthands, and it's
  // not a match to some other abbrev.
  arg = arg.replace(/^-+/, '');

  // if it's an exact known option, then don't go any further
  if (abbrevs[arg] === arg) {
    return null
  }

  // if it's an exact known shortopt, same deal
  if (shorthands[arg]) {
    // make it an array, if it's a list of words
    if (shorthands[arg] && !Array.isArray(shorthands[arg])) {
      shorthands[arg] = shorthands[arg].split(/\s+/);
    }

    return shorthands[arg]
  }

  // first check to see if this arg is a set of single-char shorthands
  const chrs = singleCharacters(arg, shorthands);
  if (chrs) {
    return chrs.map((c) => shorthands[c]).reduce((l, r) => l.concat(r), [])
  }

  // if it's an arg abbrev, and not a literal shorthand, then prefer the arg
  if (abbrevs[arg] && !shorthands[arg]) {
    return null
  }

  // if it's an abbr for a shorthand, then use that
  if (shortAbbr[arg]) {
    arg = shortAbbr[arg];
  }

  // make it an array, if it's a list of words
  if (shorthands[arg] && !Array.isArray(shorthands[arg])) {
    shorthands[arg] = shorthands[arg].split(/\s+/);
  }

  return shorthands[arg]
}

var noptLib = {
  nopt: nopt$1,
  clean,
  parse: parse$1,
  validate: validate$1,
  resolveShort,
  typeDefs: defaultTypeDefs,
};

(function (module, exports) {
	const lib = noptLib;
	const defaultTypeDefs = typeDefs$3;

	// This is the version of nopt's API that requires setting typeDefs and invalidHandler
	// on the required `nopt` object since it is a singleton. To not do a breaking change
	// an API that requires all options be passed in is located in `nopt-lib.js` and
	// exported here as lib.
	// TODO(breaking): make API only work in non-singleton mode

	module.exports = exports = nopt;
	exports.clean = clean;
	exports.typeDefs = defaultTypeDefs;
	exports.lib = lib;

	function nopt (types, shorthands, args = process.argv, slice = 2) {
	  return lib.nopt(args.slice(slice), {
	    types: types || {},
	    shorthands: shorthands || {},
	    typeDefs: exports.typeDefs,
	    invalidHandler: exports.invalidHandler,
	  })
	}

	function clean (data, types, typeDefs = exports.typeDefs) {
	  return lib.clean(data, {
	    types: types || {},
	    typeDefs,
	    invalidHandler: exports.invalidHandler,
	  })
	} 
} (nopt$2, nopt$2.exports));

var noptExports = nopt$2.exports;

const META = Symbol('proc-log.meta');
var lib$6 = {
  META: META,
  output: {
    LEVELS: [
      'standard',
      'error',
      'buffer',
      'flush',
    ],
    KEYS: {
      standard: 'standard',
      error: 'error',
      buffer: 'buffer',
      flush: 'flush',
    },
    standard: function (...args) {
      return process.emit('output', 'standard', ...args)
    },
    error: function (...args) {
      return process.emit('output', 'error', ...args)
    },
    buffer: function (...args) {
      return process.emit('output', 'buffer', ...args)
    },
    flush: function (...args) {
      return process.emit('output', 'flush', ...args)
    },
  },
  log: {
    LEVELS: [
      'notice',
      'error',
      'warn',
      'info',
      'verbose',
      'http',
      'silly',
      'timing',
      'pause',
      'resume',
    ],
    KEYS: {
      notice: 'notice',
      error: 'error',
      warn: 'warn',
      info: 'info',
      verbose: 'verbose',
      http: 'http',
      silly: 'silly',
      timing: 'timing',
      pause: 'pause',
      resume: 'resume',
    },
    error: function (...args) {
      return process.emit('log', 'error', ...args)
    },
    notice: function (...args) {
      return process.emit('log', 'notice', ...args)
    },
    warn: function (...args) {
      return process.emit('log', 'warn', ...args)
    },
    info: function (...args) {
      return process.emit('log', 'info', ...args)
    },
    verbose: function (...args) {
      return process.emit('log', 'verbose', ...args)
    },
    http: function (...args) {
      return process.emit('log', 'http', ...args)
    },
    silly: function (...args) {
      return process.emit('log', 'silly', ...args)
    },
    timing: function (...args) {
      return process.emit('log', 'timing', ...args)
    },
    pause: function () {
      return process.emit('log', 'pause')
    },
    resume: function () {
      return process.emit('log', 'resume')
    },
  },
  time: {
    LEVELS: [
      'start',
      'end',
    ],
    KEYS: {
      start: 'start',
      end: 'end',
    },
    start: function (name, fn) {
      process.emit('time', 'start', name);
      function end () {
        return process.emit('time', 'end', name)
      }
      if (typeof fn === 'function') {
        const res = fn();
        if (res && res.finally) {
          return res.finally(end)
        }
        end();
        return res
      }
      return end
    },
    end: function (name) {
      return process.emit('time', 'end', name)
    },
  },
  input: {
    LEVELS: [
      'start',
      'end',
      'read',
    ],
    KEYS: {
      start: 'start',
      end: 'end',
      read: 'read',
    },
    start: function (fn) {
      process.emit('input', 'start');
      function end () {
        return process.emit('input', 'end')
      }
      if (typeof fn === 'function') {
        const res = fn();
        if (res && res.finally) {
          return res.finally(end)
        }
        end();
        return res
      }
      return end
    },
    end: function () {
      return process.emit('input', 'end')
    },
    read: function (...args) {
      let resolve, reject;
      const promise = new Promise((_resolve, _reject) => {
        resolve = _resolve;
        reject = _reject;
      });
      process.emit('input', 'read', resolve, reject, ...args);
      return promise
    },
  },
};

var typeDefs$2 = {exports: {}};

const parse = val => {
  // this is run via nopt and parse field where everything is
  // converted to a string first, ignoring coverage for now
  // instead of figuring out what is happening under the hood in nopt
  // istanbul ignore else
  if (typeof val === 'string') {
    if (/^0o?[0-7]+$/.test(val)) {
      return parseInt(val.replace(/^0o?/, ''), 8)
    } else if (/^[1-9][0-9]*$/.test(val)) {
      return parseInt(val, 10)
    } else {
      throw new Error(`invalid umask value: ${val}`)
    }
  } else {
    if (typeof val !== 'number') {
      throw new Error(`invalid umask value: ${val}`)
    }
    val = Math.floor(val);
    if (val < 0 || val > 511) {
      throw new Error(`invalid umask value: ${val}`)
    }
    return val
  }
};

const validate = (data, k, val) => {
  try {
    data[k] = parse(val);
    return true
  } catch (er) {
    return false
  }
};

var umask = { parse, validate };

(function (module) {
	const nopt = noptExports;

	const { validate: validateUmask } = umask;

	class Umask {}
	class Semver {}
	const semverValid = valid_1;
	const validateSemver = (data, k, val) => {
	  const valid = semverValid(val);
	  if (!valid) {
	    return false
	  }
	  data[k] = valid;
	};

	const noptValidatePath = nopt.typeDefs.path.validate;
	const validatePath = (data, k, val) => {
	  if (typeof val !== 'string') {
	    return false
	  }
	  return noptValidatePath(data, k, val)
	};

	// add descriptions so we can validate more usefully
	module.exports = {
	  ...nopt.typeDefs,
	  semver: {
	    type: Semver,
	    validate: validateSemver,
	    description: 'full valid SemVer string',
	  },
	  Umask: {
	    type: Umask,
	    validate: validateUmask,
	    description: 'octal number in range 0o000..0o777 (0..511)',
	  },
	  url: {
	    ...nopt.typeDefs.url,
	    description: 'full url with "http://"',
	  },
	  path: {
	    ...nopt.typeDefs.path,
	    validate: validatePath,
	    description: 'valid filesystem path',
	  },
	  Number: {
	    ...nopt.typeDefs.Number,
	    description: 'numeric value',
	  },
	  Boolean: {
	    ...nopt.typeDefs.Boolean,
	    description: 'boolean value (true or false)',
	  },
	  Date: {
	    ...nopt.typeDefs.Date,
	    description: 'valid Date string',
	  },
	};

	// TODO: make nopt less of a global beast so this kludge isn't necessary
	nopt.typeDefs = module.exports; 
} (typeDefs$2));

var typeDefsExports = typeDefs$2.exports;

const { URL } = require$$0$4;

/**
 * Maps a URL to an identifier.
 *
 * Name courtesy schiffertronix media LLC, a New Jersey corporation
 *
 * @param {String} uri The URL to be nerfed.
 *
 * @returns {String} A nerfed URL.
 */
var nerfDart$1 = (url) => {
  const parsed = new URL(url);
  const from = `${parsed.protocol}//${parsed.host}${parsed.pathname}`;
  const rel = new URL('.', from);
  const res = `//${rel.host}${rel.pathname}`;
  return res
};

// replace any ${ENV} values with the appropriate environ.

const envExpr = /(?<!\\)(\\*)\$\{([^${}]+)\}/g;

var envReplace$2 = (f, env) => f.replace(envExpr, (orig, esc, name) => {
  const val = env[name] !== undefined ? env[name] : `$\{${name}}`;

  // consume the escape chars that are relevant.
  if (esc.length % 2) {
    return orig.slice((esc.length + 1) / 2)
  }

  return (esc.slice(esc.length / 2)) + val
});

// Parse a field, coercing it to the best type available.
const typeDefs$1 = typeDefsExports;
const envReplace$1 = envReplace$2;
const { resolve: resolve$1 } = path$1;

const { parse: umaskParse } = umask;

const parseField$1 = (f, key, opts, listElement = false) => {
  if (typeof f !== 'string' && !Array.isArray(f)) {
    return f
  }

  const { platform, types, home, env } = opts;

  // type can be array or a single thing.  coerce to array.
  const typeList = new Set([].concat(types[key]));
  const isPath = typeList.has(typeDefs$1.path.type);
  const isBool = typeList.has(typeDefs$1.Boolean.type);
  const isString = isPath || typeList.has(typeDefs$1.String.type);
  const isUmask = typeList.has(typeDefs$1.Umask.type);
  const isNumber = typeList.has(typeDefs$1.Number.type);
  const isList = !listElement && typeList.has(Array);
  const isDate = typeList.has(typeDefs$1.Date.type);

  if (Array.isArray(f)) {
    return !isList ? f : f.map(field => parseField$1(field, key, opts, true))
  }

  // now we know it's a string
  f = f.trim();

  // list types get put in the environment separated by double-\n
  // usually a single \n would suffice, but ca/cert configs can contain
  // line breaks and multiple entries.
  if (isList) {
    return parseField$1(f.split('\n\n'), key, opts)
  }

  // --foo is like --foo=true for boolean types
  if (isBool && !isString && f === '') {
    return true
  }

  // string types can be the string 'true', 'false', etc.
  // otherwise, parse these values out
  if (!isString && !isPath && !isNumber) {
    switch (f) {
      case 'true': return true
      case 'false': return false
      case 'null': return null
      case 'undefined': return undefined
    }
  }

  f = envReplace$1(f, env);

  if (isDate) {
    return new Date(f)
  }

  if (isPath) {
    const homePattern = platform === 'win32' ? /^~(\/|\\)/ : /^~\//;
    if (homePattern.test(f) && home) {
      f = resolve$1(home, f.slice(2));
    } else {
      f = resolve$1(f);
    }
  }

  if (isUmask) {
    try {
      return umaskParse(f)
    } catch (er) {
      // let it warn later when we validate
      return f
    }
  }

  if (isNumber && !isNaN(f)) {
    f = +f;
  }

  return f
};

var parseField_1 = parseField$1;

// Set environment variables for any non-default configs,
// so that they're already there when we run lifecycle scripts.
//
// See https://github.com/npm/rfcs/pull/90

// Return the env key if this is a thing that belongs in the env.
// Ie, if the key isn't a @scope, //nerf.dart, or _private,
// and the value is a string or array.  Otherwise return false.
const envKey = (key, val) => {
  return !/^[/@_]/.test(key) &&
    (typeof envVal(val) === 'string') &&
      `npm_config_${key.replace(/-/g, '_').toLowerCase()}`
};

const envVal = val => Array.isArray(val) ? val.map(v => envVal(v)).join('\n\n')
  : val === null || val === undefined || val === false ? ''
  : typeof val === 'object' ? null
  : String(val);

const sameConfigValue = (def, val) =>
  !Array.isArray(val) || !Array.isArray(def) ? def === val
  : sameArrayValue(def, val);

const sameArrayValue = (def, val) => {
  if (def.length !== val.length) {
    return false
  }

  for (let i = 0; i < def.length; i++) {
    /* istanbul ignore next - there are no array configs where the default
     * is not an empty array, so this loop is a no-op, but it's the correct
     * thing to do if we ever DO add a config like that. */
    if (def[i] !== val[i]) {
      return false
    }
  }
  return true
};

const setEnv = (env, rawKey, rawVal) => {
  const val = envVal(rawVal);
  const key = envKey(rawKey, val);
  if (key && val !== null) {
    env[key] = val;
  }
};

const setEnvs$1 = (config) => {
  // This ensures that all npm config values that are not the defaults are
  // shared appropriately with child processes, without false positives.
  const {
    env,
    defaults,
    definitions,
    list: [cliConf, envConf],
  } = config;

  env.INIT_CWD = process.cwd();

  // if the key is deprecated, skip it always.
  // if the key is the default value,
  //   if the environ is NOT the default value,
  //     set the environ
  //   else skip it, it's fine
  // if the key is NOT the default value,
  //   if the env is setting it, then leave it (already set)
  //   otherwise, set the env
  const cliSet = new Set(Object.keys(cliConf));
  const envSet = new Set(Object.keys(envConf));
  for (const key in cliConf) {
    const { deprecated, envExport = true } = definitions[key] || {};
    if (deprecated || envExport === false) {
      continue
    }

    if (sameConfigValue(defaults[key], cliConf[key])) {
      // config is the default, if the env thought different, then we
      // have to set it BACK to the default in the environment.
      if (!sameConfigValue(envConf[key], cliConf[key])) {
        setEnv(env, key, cliConf[key]);
      }
    } else {
      // config is not the default.  if the env wasn't the one to set
      // it that way, then we have to put it in the env
      if (!(envSet.has(key) && !cliSet.has(key))) {
        setEnv(env, key, cliConf[key]);
      }
    }
  }

  // also set some other common nice envs that we want to rely on
  env.HOME = config.home;
  env.npm_config_global_prefix = config.globalPrefix;
  env.npm_config_local_prefix = config.localPrefix;
  if (cliConf.editor) {
    env.EDITOR = cliConf.editor;
  }

  // note: this doesn't afect the *current* node process, of course, since
  // it's already started, but it does affect the options passed to scripts.
  if (cliConf['node-options']) {
    env.NODE_OPTIONS = cliConf['node-options'];
  }
  env.npm_execpath = config.npmBin;
  env.NODE = env.npm_node_execpath = config.execPath;
};

var setEnvs_1 = setEnvs$1;

var errors;
var hasRequiredErrors;

function requireErrors () {
	if (hasRequiredErrors) return errors;
	hasRequiredErrors = 1;

	class ErrInvalidAuth extends Error {
	  constructor (problems) {
	    let message = 'Invalid auth configuration found: ';
	    message += problems.map((problem) => {
	      // istanbul ignore else
	      if (problem.action === 'delete') {
	        return `\`${problem.key}\` is not allowed in ${problem.where} config`
	      } else if (problem.action === 'rename') {
	        return `\`${problem.from}\` must be renamed to \`${problem.to}\` in ${problem.where} config`
	      }
	    }).join(', ');
	    message += '\nPlease run `npm config fix` to repair your configuration.`';
	    super(message);
	    this.code = 'ERR_INVALID_AUTH';
	    this.problems = problems;
	  }
	}

	errors = {
	  ErrInvalidAuth,
	};
	return errors;
}

var typeDescription_1;
var hasRequiredTypeDescription;

function requireTypeDescription () {
	if (hasRequiredTypeDescription) return typeDescription_1;
	hasRequiredTypeDescription = 1;
	// return the description of the valid values of a field
	// returns a string for one thing, or an array of descriptions
	const typeDefs = typeDefsExports;
	const typeDescription = t => {
	  if (!t || typeof t !== 'function' && typeof t !== 'object') {
	    return t
	  }

	  if (Array.isArray(t)) {
	    return t.map(t => typeDescription(t))
	  }

	  for (const { type, description } of Object.values(typeDefs)) {
	    if (type === t) {
	      return description || type
	    }
	  }

	  return t
	};
	typeDescription_1 = t => [].concat(typeDescription(t)).filter(t => t !== undefined);
	return typeDescription_1;
}

var lib$5;
var hasRequiredLib$4;

function requireLib$4 () {
	if (hasRequiredLib$4) return lib$5;
	hasRequiredLib$4 = 1;

	const hexify = char => {
	  const h = char.charCodeAt(0).toString(16).toUpperCase();
	  return '0x' + (h.length % 2 ? '0' : '') + h
	};

	const parseError = (e, txt, context) => {
	  if (!txt) {
	    return {
	      message: e.message + ' while parsing empty string',
	      position: 0,
	    }
	  }
	  const badToken = e.message.match(/^Unexpected token (.) .*position\s+(\d+)/i);
	  const errIdx = badToken ? +badToken[2]
	    : e.message.match(/^Unexpected end of JSON.*/i) ? txt.length - 1
	    : null;

	  const msg = badToken ? e.message.replace(/^Unexpected token ./, `Unexpected token ${
	      JSON.stringify(badToken[1])
	    } (${hexify(badToken[1])})`)
	    : e.message;

	  if (errIdx !== null && errIdx !== undefined) {
	    const start = errIdx <= context ? 0
	      : errIdx - context;

	    const end = errIdx + context >= txt.length ? txt.length
	      : errIdx + context;

	    const slice = (start === 0 ? '' : '...') +
	      txt.slice(start, end) +
	      (end === txt.length ? '' : '...');

	    const near = txt === slice ? '' : 'near ';

	    return {
	      message: msg + ` while parsing ${near}${JSON.stringify(slice)}`,
	      position: errIdx,
	    }
	  } else {
	    return {
	      message: msg + ` while parsing '${txt.slice(0, context * 2)}'`,
	      position: 0,
	    }
	  }
	};

	class JSONParseError extends SyntaxError {
	  constructor (er, txt, context, caller) {
	    context = context || 20;
	    const metadata = parseError(er, txt, context);
	    super(metadata.message);
	    Object.assign(this, metadata);
	    this.code = 'EJSONPARSE';
	    this.systemError = er;
	    Error.captureStackTrace(this, caller || this.constructor);
	  }

	  get name () {
	    return this.constructor.name
	  }

	  set name (n) {}
	  get [Symbol.toStringTag] () {
	    return this.constructor.name
	  }
	}

	const kIndent = Symbol.for('indent');
	const kNewline = Symbol.for('newline');
	// only respect indentation if we got a line break, otherwise squash it
	// things other than objects and arrays aren't indented, so ignore those
	// Important: in both of these regexps, the $1 capture group is the newline
	// or undefined, and the $2 capture group is the indent, or undefined.
	const formatRE = /^\s*[{[]((?:\r?\n)+)([\s\t]*)/;
	const emptyRE = /^(?:\{\}|\[\])((?:\r?\n)+)?$/;

	const parseJson = (txt, reviver, context) => {
	  const parseText = stripBOM(txt);
	  context = context || 20;
	  try {
	    // get the indentation so that we can save it back nicely
	    // if the file starts with {" then we have an indent of '', ie, none
	    // otherwise, pick the indentation of the next line after the first \n
	    // If the pattern doesn't match, then it means no indentation.
	    // JSON.stringify ignores symbols, so this is reasonably safe.
	    // if the string is '{}' or '[]', then use the default 2-space indent.
	    const [, newline = '\n', indent = '  '] = parseText.match(emptyRE) ||
	      parseText.match(formatRE) ||
	      [null, '', ''];

	    const result = JSON.parse(parseText, reviver);
	    if (result && typeof result === 'object') {
	      result[kNewline] = newline;
	      result[kIndent] = indent;
	    }
	    return result
	  } catch (e) {
	    if (typeof txt !== 'string' && !Buffer.isBuffer(txt)) {
	      const isEmptyArray = Array.isArray(txt) && txt.length === 0;
	      throw Object.assign(new TypeError(
	        `Cannot parse ${isEmptyArray ? 'an empty array' : String(txt)}`
	      ), {
	        code: 'EJSONPARSE',
	        systemError: e,
	      })
	    }

	    throw new JSONParseError(e, parseText, context, parseJson)
	  }
	};

	// Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)
	// because the buffer-to-string conversion in `fs.readFileSync()`
	// translates it to FEFF, the UTF-16 BOM.
	const stripBOM = txt => String(txt).replace(/^\uFEFF/, '');

	lib$5 = parseJson;
	parseJson.JSONParseError = JSONParseError;

	parseJson.noExceptions = (txt, reviver) => {
	  try {
	    return JSON.parse(stripBOM(txt), reviver)
	  } catch (e) {
	    // no exceptions
	  }
	};
	return lib$5;
}

var lib$4;
var hasRequiredLib$3;

function requireLib$3 () {
	if (hasRequiredLib$3) return lib$4;
	hasRequiredLib$3 = 1;
	// pass in a manifest with a 'bin' field here, and it'll turn it
	// into a properly santized bin object
	const { join, basename } = require$$0;

	const normalize = pkg =>
	  !pkg.bin ? removeBin(pkg)
	  : typeof pkg.bin === 'string' ? normalizeString(pkg)
	  : Array.isArray(pkg.bin) ? normalizeArray(pkg)
	  : typeof pkg.bin === 'object' ? normalizeObject(pkg)
	  : removeBin(pkg);

	const normalizeString = pkg => {
	  if (!pkg.name) {
	    return removeBin(pkg)
	  }
	  pkg.bin = { [pkg.name]: pkg.bin };
	  return normalizeObject(pkg)
	};

	const normalizeArray = pkg => {
	  pkg.bin = pkg.bin.reduce((acc, k) => {
	    acc[basename(k)] = k;
	    return acc
	  }, {});
	  return normalizeObject(pkg)
	};

	const removeBin = pkg => {
	  delete pkg.bin;
	  return pkg
	};

	const normalizeObject = pkg => {
	  const orig = pkg.bin;
	  const clean = {};
	  let hasBins = false;
	  Object.keys(orig).forEach(binKey => {
	    const base = join('/', basename(binKey.replace(/\\|:/g, '/'))).slice(1);

	    if (typeof orig[binKey] !== 'string' || !base) {
	      return
	    }

	    const binTarget = join('/', orig[binKey].replace(/\\/g, '/'))
	      .replace(/\\/g, '/').slice(1);

	    if (!binTarget) {
	      return
	    }

	    clean[base] = binTarget;
	    hasBins = true;
	  });

	  if (hasBins) {
	    pkg.bin = clean;
	  } else {
	    delete pkg.bin;
	  }

	  return pkg
	};

	lib$4 = normalize;
	return lib$4;
}

var lib$3;
var hasRequiredLib$2;

function requireLib$2 () {
	if (hasRequiredLib$2) return lib$3;
	hasRequiredLib$2 = 1;
	const { readFile, lstat, readdir } = require$$0$5;
	const parse = requireLib$4();
	const normalizePackageBin = requireLib$3();
	const { resolve, dirname, join, relative } = require$$0;

	const rpj = path => readFile(path, 'utf8')
	  .then(data => readBinDir(path, normalize(stripUnderscores(parse(data)))))
	  .catch(er => {
	    er.path = path;
	    throw er
	  });

	// load the directories.bin folder as a 'bin' object
	const readBinDir = async (path, data) => {
	  if (data.bin) {
	    return data
	  }

	  const m = data.directories && data.directories.bin;
	  if (!m || typeof m !== 'string') {
	    return data
	  }

	  // cut off any monkey business, like setting directories.bin
	  // to ../../../etc/passwd or /etc/passwd or something like that.
	  const root = dirname(path);
	  const dir = join('.', join('/', m));
	  data.bin = await walkBinDir(root, dir, {});
	  return data
	};

	const walkBinDir = async (root, dir, obj) => {
	  const entries = await readdir(resolve(root, dir)).catch(() => []);
	  for (const entry of entries) {
	    if (entry.charAt(0) === '.') {
	      continue
	    }
	    const f = resolve(root, dir, entry);
	    // ignore stat errors, weird file types, symlinks, etc.
	    const st = await lstat(f).catch(() => null);
	    if (!st) {
	      continue
	    } else if (st.isFile()) {
	      obj[entry] = relative(root, f);
	    } else if (st.isDirectory()) {
	      await walkBinDir(root, join(dir, entry), obj);
	    }
	  }
	  return obj
	};

	// do not preserve _fields set in files, they are sus
	const stripUnderscores = data => {
	  for (const key of Object.keys(data).filter(k => /^_/.test(k))) {
	    delete data[key];
	  }
	  return data
	};

	const normalize = data => {
	  addId(data);
	  fixBundled(data);
	  pruneRepeatedOptionals(data);
	  fixScripts(data);
	  fixFunding(data);
	  normalizePackageBin(data);
	  return data
	};

	rpj.normalize = normalize;

	const addId = data => {
	  if (data.name && data.version) {
	    data._id = `${data.name}@${data.version}`;
	  }
	  return data
	};

	// it was once common practice to list deps both in optionalDependencies
	// and in dependencies, to support npm versions that did not know abbout
	// optionalDependencies.  This is no longer a relevant need, so duplicating
	// the deps in two places is unnecessary and excessive.
	const pruneRepeatedOptionals = data => {
	  const od = data.optionalDependencies;
	  const dd = data.dependencies || {};
	  if (od && typeof od === 'object') {
	    for (const name of Object.keys(od)) {
	      delete dd[name];
	    }
	  }
	  if (Object.keys(dd).length === 0) {
	    delete data.dependencies;
	  }
	  return data
	};

	const fixBundled = data => {
	  const bdd = data.bundledDependencies;
	  const bd = data.bundleDependencies === undefined ? bdd
	    : data.bundleDependencies;

	  if (bd === false) {
	    data.bundleDependencies = [];
	  } else if (bd === true) {
	    data.bundleDependencies = Object.keys(data.dependencies || {});
	  } else if (bd && typeof bd === 'object') {
	    if (!Array.isArray(bd)) {
	      data.bundleDependencies = Object.keys(bd);
	    } else {
	      data.bundleDependencies = bd;
	    }
	  } else {
	    delete data.bundleDependencies;
	  }

	  delete data.bundledDependencies;
	  return data
	};

	const fixScripts = data => {
	  if (!data.scripts || typeof data.scripts !== 'object') {
	    delete data.scripts;
	    return data
	  }

	  for (const [name, script] of Object.entries(data.scripts)) {
	    if (typeof script !== 'string') {
	      delete data.scripts[name];
	    }
	  }
	  return data
	};

	const fixFunding = data => {
	  if (data.funding && typeof data.funding === 'string') {
	    data.funding = { url: data.funding };
	  }
	  return data
	};

	lib$3 = rpj;
	return lib$3;
}

var lib$2;
var hasRequiredLib$1;

function requireLib$1 () {
	if (hasRequiredLib$1) return lib$2;
	hasRequiredLib$1 = 1;
	const { basename, dirname } = require$$0;

	const getName = (parent, base) =>
	  parent.charAt(0) === '@' ? `${parent}/${base}` : base;

	lib$2 = dir => dir ? getName(basename(dirname(dir)), basename(dir))
	  : false;
	return lib$2;
}

var lib$1;
var hasRequiredLib;

function requireLib () {
	if (hasRequiredLib) return lib$1;
	hasRequiredLib = 1;
	const path = require$$0;

	const getName = requireLib$1();
	const { minimatch } = requireCommonjs();
	const rpj = requireLib$2();
	const { glob } = requireCommonjs$1();

	function appendNegatedPatterns (patterns) {
	  const results = [];
	  for (let pattern of patterns) {
	    const excl = pattern.match(/^!+/);
	    if (excl) {
	      pattern = pattern.slice(excl[0].length);
	    }

	    // strip off any / from the start of the pattern.  /foo => foo
	    pattern = pattern.replace(/^\/+/, '');

	    // an odd number of ! means a negated pattern.  !!foo ==> foo
	    const negate = excl && excl[0].length % 2 === 1;
	    results.push({ pattern, negate });
	  }

	  return results
	}

	function getPatterns (workspaces) {
	  const workspacesDeclaration =
	    Array.isArray(workspaces.packages)
	      ? workspaces.packages
	      : workspaces;

	  if (!Array.isArray(workspacesDeclaration)) {
	    throw getError({
	      message: 'workspaces config expects an Array',
	      code: 'EWORKSPACESCONFIG',
	    })
	  }

	  return appendNegatedPatterns(workspacesDeclaration)
	}

	function getPackageName (pkg, pathname) {
	  const { name } = pkg;
	  return name || getName(pathname)
	}

	function pkgPathmame (opts) {
	  return (...args) => {
	    const cwd = opts.cwd ? opts.cwd : process.cwd();
	    return path.join.apply(null, [cwd, ...args])
	  }
	}

	// make sure glob pattern only matches folders
	function getGlobPattern (pattern) {
	  pattern = pattern.replace(/\\/g, '/');
	  return pattern.endsWith('/')
	    ? pattern
	    : `${pattern}/`
	}

	function getError ({ Type = TypeError, message, code }) {
	  return Object.assign(new Type(message), { code })
	}

	function reverseResultMap (map) {
	  return new Map(Array.from(map, item => item.reverse()))
	}

	async function mapWorkspaces (opts = {}) {
	  if (!opts || !opts.pkg) {
	    throw getError({
	      message: 'mapWorkspaces missing pkg info',
	      code: 'EMAPWORKSPACESPKG',
	    })
	  }

	  const { workspaces = [] } = opts.pkg;
	  const patterns = getPatterns(workspaces);
	  const results = new Map();
	  const seen = new Map();

	  if (!patterns.length) {
	    return results
	  }

	  const getGlobOpts = () => ({
	    ...opts,
	    ignore: [
	      ...opts.ignore || [],
	      ...['**/node_modules/**'],
	    ],
	  });

	  const getPackagePathname = pkgPathmame(opts);

	  for (const item of patterns) {
	    let matches = await glob(getGlobPattern(item.pattern), getGlobOpts());
	    // preserves glob@8 behavior
	    matches = matches.sort((a, b) => a.localeCompare(b, 'en'));

	    for (const match of matches) {
	      let pkg;
	      const packageJsonPathname = getPackagePathname(match, 'package.json');
	      const packagePathname = path.dirname(packageJsonPathname);

	      try {
	        pkg = await rpj(packageJsonPathname);
	      } catch (err) {
	        if (err.code === 'ENOENT') {
	          continue
	        } else {
	          throw err
	        }
	      }

	      const name = getPackageName(pkg, packagePathname);

	      let seenPackagePathnames = seen.get(name);
	      if (!seenPackagePathnames) {
	        seenPackagePathnames = new Set();
	        seen.set(name, seenPackagePathnames);
	      }
	      if (item.negate) {
	        seenPackagePathnames.delete(packagePathname);
	      } else {
	        seenPackagePathnames.add(packagePathname);
	      }
	    }
	  }

	  const errorMessageArray = ['must not have multiple workspaces with the same name'];
	  for (const [packageName, seenPackagePathnames] of seen) {
	    if (seenPackagePathnames.size === 0) {
	      continue
	    }
	    if (seenPackagePathnames.size > 1) {
	      addDuplicateErrorMessages(errorMessageArray, packageName, seenPackagePathnames);
	    } else {
	      results.set(packageName, seenPackagePathnames.values().next().value);
	    }
	  }

	  if (errorMessageArray.length > 1) {
	    throw getError({
	      Type: Error,
	      message: errorMessageArray.join('\n'),
	      code: 'EDUPLICATEWORKSPACE',
	    })
	  }

	  return results
	}

	function addDuplicateErrorMessages (messageArray, packageName, packagePathnames) {
	  messageArray.push(
	    `package '${packageName}' has conflicts in the following paths:`
	  );

	  for (const packagePathname of packagePathnames) {
	    messageArray.push(
	      '    ' + packagePathname
	    );
	  }
	}

	mapWorkspaces.virtual = function (opts = {}) {
	  if (!opts || !opts.lockfile) {
	    throw getError({
	      message: 'mapWorkspaces.virtual missing lockfile info',
	      code: 'EMAPWORKSPACESLOCKFILE',
	    })
	  }

	  const { packages = {} } = opts.lockfile;
	  const { workspaces = [] } = packages[''] || {};
	  // uses a pathname-keyed map in order to negate the exact items
	  const results = new Map();
	  const patterns = getPatterns(workspaces);
	  if (!patterns.length) {
	    return results
	  }
	  patterns.push({ pattern: '**/node_modules/**', negate: true });

	  const getPackagePathname = pkgPathmame(opts);

	  for (const packageKey of Object.keys(packages)) {
	    if (packageKey === '') {
	      continue
	    }

	    for (const item of patterns) {
	      if (minimatch(packageKey, item.pattern)) {
	        const packagePathname = getPackagePathname(packageKey);
	        const name = getPackageName(packages[packageKey], packagePathname);

	        if (item.negate) {
	          results.delete(packagePathname);
	        } else {
	          results.set(packagePathname, name);
	        }
	      }
	    }
	  }

	  // Invert pathname-keyed to a proper name-to-pathnames Map
	  return reverseResultMap(results)
	};

	lib$1 = mapWorkspaces;
	return lib$1;
}

// TODO: set the scope config from package.json or explicit cli config
const { walkUp } = cjs;
const ini = ini$1;
const nopt = noptExports;
const { log, time } = lib$6;

const { resolve, dirname, join } = path$1;
const { homedir } = os$1;
const {
  readFile,
  writeFile,
  chmod,
  unlink,
  stat,
  mkdir,
} = require$$0$5;

const fileExists = (...p) => stat(resolve(...p))
  .then((st) => st.isFile())
  .catch(() => false);

const dirExists = (...p) => stat(resolve(...p))
  .then((st) => st.isDirectory())
  .catch(() => false);

const hasOwnProperty = (obj, key) =>
  Object.prototype.hasOwnProperty.call(obj, key);

const typeDefs = typeDefsExports;
const nerfDart = nerfDart$1;
const envReplace = envReplace$2;
const parseField = parseField_1;
const setEnvs = setEnvs_1;

// types that can be saved back to
const confFileTypes = new Set([
  'global',
  'user',
  'project',
]);

const confTypes = new Set([
  'default',
  'builtin',
  ...confFileTypes,
  'env',
  'cli',
]);

class Config {
  #loaded = false
  #flatten
  // populated the first time we flatten the object
  #flatOptions = null

  static get typeDefs () {
    return typeDefs
  }

  constructor ({
    definitions,
    shorthands,
    flatten,
    npmPath,

    // options just to override in tests, mostly
    env = process.env,
    argv = process.argv,
    platform = process.platform,
    execPath = process.execPath,
    cwd = process.cwd(),
    excludeNpmCwd = false,
  }) {
    // turn the definitions into nopt's weirdo syntax
    this.definitions = definitions;
    const types = {};
    const defaults = {};
    this.deprecated = {};
    for (const [key, def] of Object.entries(definitions)) {
      defaults[key] = def.default;
      types[key] = def.type;
      if (def.deprecated) {
        this.deprecated[key] = def.deprecated.trim().replace(/\n +/, '\n');
      }
    }

    this.#flatten = flatten;
    this.types = types;
    this.shorthands = shorthands;
    this.defaults = defaults;

    this.npmPath = npmPath;
    this.npmBin = join(this.npmPath, 'bin/npm-cli.js');
    this.argv = argv;
    this.env = env;
    this.execPath = execPath;
    this.platform = platform;
    this.cwd = cwd;
    this.excludeNpmCwd = excludeNpmCwd;

    // set when we load configs
    this.globalPrefix = null;
    this.localPrefix = null;
    this.localPackage = null;

    // defaults to env.HOME, but will always be *something*
    this.home = null;

    // set up the prototype chain of config objects
    const wheres = [...confTypes];
    this.data = new Map();
    let parent = null;
    for (const where of wheres) {
      this.data.set(where, parent = new ConfigData(parent));
    }

    this.data.set = () => {
      throw new Error('cannot change internal config data structure')
    };
    this.data.delete = () => {
      throw new Error('cannot change internal config data structure')
    };

    this.sources = new Map([]);

    this.list = [];
    for (const { data } of this.data.values()) {
      this.list.unshift(data);
    }
    Object.freeze(this.list);

    this.#loaded = false;
  }

  get loaded () {
    return this.#loaded
  }

  get prefix () {
    return this.#get('global') ? this.globalPrefix : this.localPrefix
  }

  // return the location where key is found.
  find (key) {
    if (!this.loaded) {
      throw new Error('call config.load() before reading values')
    }

    // have to look in reverse order
    const entries = [...this.data.entries()];
    for (let i = entries.length - 1; i > -1; i--) {
      const [where, { data }] = entries[i];
      if (hasOwnProperty(data, key)) {
        return where
      }
    }
    return null
  }

  get (key, where) {
    if (!this.loaded) {
      throw new Error('call config.load() before reading values')
    }
    return this.#get(key, where)
  }

  // we need to get values sometimes, so use this internal one to do so
  // while in the process of loading.
  #get (key, where = null) {
    if (where !== null && !confTypes.has(where)) {
      throw new Error('invalid config location param: ' + where)
    }
    const { data } = this.data.get(where || 'cli');
    return where === null || hasOwnProperty(data, key) ? data[key] : undefined
  }

  set (key, val, where = 'cli') {
    if (!this.loaded) {
      throw new Error('call config.load() before setting values')
    }
    if (!confTypes.has(where)) {
      throw new Error('invalid config location param: ' + where)
    }
    this.#checkDeprecated(key);
    const { data, raw } = this.data.get(where);
    data[key] = val;
    if (['global', 'user', 'project'].includes(where)) {
      raw[key] = val;
    }

    // this is now dirty, the next call to this.valid will have to check it
    this.data.get(where)[_valid] = null;

    // the flat options are invalidated, regenerate next time they're needed
    this.#flatOptions = null;
  }

  get flat () {
    if (this.#flatOptions) {
      return this.#flatOptions
    }

    // create the object for flat options passed to deps
    const timeEnd = time.start('config:load:flatten');
    this.#flatOptions = {};
    // walk from least priority to highest
    for (const { data } of this.data.values()) {
      this.#flatten(data, this.#flatOptions);
    }
    this.#flatOptions.nodeBin = this.execPath;
    this.#flatOptions.npmBin = this.npmBin;
    timeEnd();

    return this.#flatOptions
  }

  delete (key, where = 'cli') {
    if (!this.loaded) {
      throw new Error('call config.load() before deleting values')
    }
    if (!confTypes.has(where)) {
      throw new Error('invalid config location param: ' + where)
    }
    const { data, raw } = this.data.get(where);
    delete data[key];
    if (['global', 'user', 'project'].includes(where)) {
      delete raw[key];
    }
  }

  async load () {
    if (this.loaded) {
      throw new Error('attempting to load npm config multiple times')
    }

    // first load the defaults, which sets the global prefix
    this.loadDefaults();

    // next load the builtin config, as this sets new effective defaults
    await this.loadBuiltinConfig();

    // cli and env are not async, and can set the prefix, relevant to project
    this.loadCLI();
    this.loadEnv();

    // next project config, which can affect userconfig location
    await this.loadProjectConfig();

    // then user config, which can affect globalconfig location
    await this.loadUserConfig();

    // last but not least, global config file
    await this.loadGlobalConfig();

    // set this before calling setEnvs, so that we don't have to share
    // private attributes, as that module also does a bunch of get operations
    this.#loaded = true;

    // set proper globalPrefix now that everything is loaded
    this.globalPrefix = this.get('prefix');

    this.setEnvs();
  }

  loadDefaults () {
    this.loadGlobalPrefix();
    this.loadHome();

    const defaultsObject = {
      ...this.defaults,
      prefix: this.globalPrefix,
    };

    try {
      defaultsObject['npm-version'] = commonjsRequire(join(this.npmPath, 'package.json')).version;
    } catch {
      // in some weird state where the passed in npmPath does not have a package.json
      // this will never happen in npm, but is guarded here in case this is consumed
      // in other ways + tests
    }

    this.#loadObject(defaultsObject, 'default', 'default values');

    const { data } = this.data.get('default');

    // if the prefix is set on cli, env, or userconfig, then we need to
    // default the globalconfig file to that location, instead of the default
    // global prefix.  It's weird that `npm get globalconfig --prefix=/foo`
    // returns `/foo/etc/npmrc`, but better to not change it at this point.
    // define a custom getter, but turn into a normal prop
    // if we set it.  otherwise it can't be set on child objects
    Object.defineProperty(data, 'globalconfig', {
      get: () => resolve(this.#get('prefix'), 'etc/npmrc'),
      set (value) {
        Object.defineProperty(data, 'globalconfig', {
          value,
          configurable: true,
          writable: true,
          enumerable: true,
        });
      },
      configurable: true,
      enumerable: true,
    });
  }

  loadHome () {
    this.home = this.env.HOME || homedir();
  }

  loadGlobalPrefix () {
    if (this.globalPrefix) {
      throw new Error('cannot load default global prefix more than once')
    }

    if (this.env.PREFIX) {
      this.globalPrefix = this.env.PREFIX;
    } else if (this.platform === 'win32') {
      // c:\node\node.exe --> prefix=c:\node\
      this.globalPrefix = dirname(this.execPath);
    } else {
      // /usr/local/bin/node --> prefix=/usr/local
      this.globalPrefix = dirname(dirname(this.execPath));

      // destdir only is respected on Unix
      if (this.env.DESTDIR) {
        this.globalPrefix = join(this.env.DESTDIR, this.globalPrefix);
      }
    }
  }

  loadEnv () {
    const conf = Object.create(null);
    for (const [envKey, envVal] of Object.entries(this.env)) {
      if (!/^npm_config_/i.test(envKey) || envVal === '') {
        continue
      }
      let key = envKey.slice('npm_config_'.length);
      if (!key.startsWith('//')) { // don't normalize nerf-darted keys
        key = key.replace(/(?!^)_/g, '-') // don't replace _ at the start of the key
          .toLowerCase();
      }
      conf[key] = envVal;
    }
    this.#loadObject(conf, 'env', 'environment');
  }

  loadCLI () {
    nopt.invalidHandler = (k, val, type) =>
      this.invalidHandler(k, val, type, 'command line options', 'cli');
    const conf = nopt(this.types, this.shorthands, this.argv);
    nopt.invalidHandler = null;
    this.parsedArgv = conf.argv;
    delete conf.argv;
    this.#loadObject(conf, 'cli', 'command line options');
  }

  get valid () {
    for (const [where, { valid }] of this.data.entries()) {
      if (valid === false || valid === null && !this.validate(where)) {
        return false
      }
    }
    return true
  }

  validate (where) {
    if (!where) {
      let valid = true;
      const authProblems = [];

      for (const entryWhere of this.data.keys()) {
        // no need to validate our defaults, we know they're fine
        // cli was already validated when parsed the first time
        if (entryWhere === 'default' || entryWhere === 'builtin' || entryWhere === 'cli') {
          continue
        }
        const ret = this.validate(entryWhere);
        valid = valid && ret;

        if (['global', 'user', 'project'].includes(entryWhere)) {
          // after validating everything else, we look for old auth configs we no longer support
          // if these keys are found, we build up a list of them and the appropriate action and
          // attach it as context on the thrown error

          // first, keys that should be removed
          for (const key of ['_authtoken', '-authtoken']) {
            if (this.get(key, entryWhere)) {
              authProblems.push({ action: 'delete', key, where: entryWhere });
            }
          }

          // NOTE we pull registry without restricting to the current 'where' because we want to
          // suggest scoping things to the registry they would be applied to, which is the default
          // regardless of where it was defined
          const nerfedReg = nerfDart(this.get('registry'));
          // keys that should be nerfed but currently are not
          for (const key of ['_auth', '_authToken', 'username', '_password']) {
            if (this.get(key, entryWhere)) {
              // username and _password must both exist in the same file to be recognized correctly
              if (key === 'username' && !this.get('_password', entryWhere)) {
                authProblems.push({ action: 'delete', key, where: entryWhere });
              } else if (key === '_password' && !this.get('username', entryWhere)) {
                authProblems.push({ action: 'delete', key, where: entryWhere });
              } else {
                authProblems.push({
                  action: 'rename',
                  from: key,
                  to: `${nerfedReg}:${key}`,
                  where: entryWhere,
                });
              }
            }
          }
        }
      }

      if (authProblems.length) {
        const { ErrInvalidAuth } = requireErrors();
        throw new ErrInvalidAuth(authProblems)
      }

      return valid
    } else {
      const obj = this.data.get(where);
      obj[_valid] = true;

      nopt.invalidHandler = (k, val, type) =>
        this.invalidHandler(k, val, type, obj.source, where);

      nopt.clean(obj.data, this.types, typeDefs);

      nopt.invalidHandler = null;
      return obj[_valid]
    }
  }

  // fixes problems identified by validate(), accepts the 'problems' property from a thrown
  // ErrInvalidAuth to avoid having to check everything again
  repair (problems) {
    if (!problems) {
      try {
        this.validate();
      } catch (err) {
        // coverage skipped here because we don't need to test re-throwing an error
        // istanbul ignore next
        if (err.code !== 'ERR_INVALID_AUTH') {
          throw err
        }

        problems = err.problems;
      } finally {
        if (!problems) {
          problems = [];
        }
      }
    }

    for (const problem of problems) {
      // coverage disabled for else branch because it doesn't do anything and shouldn't
      // istanbul ignore else
      if (problem.action === 'delete') {
        this.delete(problem.key, problem.where);
      } else if (problem.action === 'rename') {
        const raw = this.data.get(problem.where).raw?.[problem.from];
        const calculated = this.get(problem.from, problem.where);
        this.set(problem.to, raw || calculated, problem.where);
        this.delete(problem.from, problem.where);
      }
    }
  }

  // Returns true if the value is coming directly from the source defined
  // in default definitions, if the current value for the key config is
  // coming from any other different source, returns false
  isDefault (key) {
    const [defaultType, ...types] = [...confTypes];
    const defaultData = this.data.get(defaultType).data;

    return hasOwnProperty(defaultData, key)
      && types.every(type => {
        const typeData = this.data.get(type).data;
        return !hasOwnProperty(typeData, key)
      })
  }

  invalidHandler (k, val, type, source, where) {
    const typeDescription = requireTypeDescription();
    log.warn(
      'invalid config',
      k + '=' + JSON.stringify(val),
      `set in ${source}`
    );
    this.data.get(where)[_valid] = false;

    if (Array.isArray(type)) {
      if (type.includes(typeDefs.url.type)) {
        type = typeDefs.url.type;
      } else {
        /* istanbul ignore if - no actual configs matching this, but
         * path types SHOULD be handled this way, like URLs, for the
         * same reason */
        if (type.includes(typeDefs.path.type)) {
          type = typeDefs.path.type;
        }
      }
    }

    const typeDesc = typeDescription(type);
    const mustBe = typeDesc
      .filter(m => m !== undefined && m !== Array);
    const msg = 'Must be' + this.#getOneOfKeywords(mustBe, typeDesc);
    const desc = mustBe.length === 1 ? mustBe[0]
      : [...new Set(mustBe.map(n => typeof n === 'string' ? n : JSON.stringify(n)))].join(', ');
    log.warn('invalid config', msg, desc);
  }

  #getOneOfKeywords (mustBe, typeDesc) {
    let keyword;
    if (mustBe.length === 1 && typeDesc.includes(Array)) {
      keyword = ' one or more';
    } else if (mustBe.length > 1 && typeDesc.includes(Array)) {
      keyword = ' one or more of:';
    } else if (mustBe.length > 1) {
      keyword = ' one of:';
    } else {
      keyword = '';
    }
    return keyword
  }

  #loadObject (obj, where, source, er = null) {
    // obj is the raw data read from the file
    const conf = this.data.get(where);
    if (conf.source) {
      const m = `double-loading "${where}" configs from ${source}, ` +
        `previously loaded from ${conf.source}`;
      throw new Error(m)
    }

    if (this.sources.has(source)) {
      const m = `double-loading config "${source}" as "${where}", ` +
        `previously loaded as "${this.sources.get(source)}"`;
      throw new Error(m)
    }

    conf.source = source;
    this.sources.set(source, where);
    if (er) {
      conf.loadError = er;
      if (er.code !== 'ENOENT') {
        log.verbose('config', `error loading ${where} config`, er);
      }
    } else {
      conf.raw = obj;
      for (const [key, value] of Object.entries(obj)) {
        const k = envReplace(key, this.env);
        const v = this.parseField(value, k);
        if (where !== 'default') {
          this.#checkDeprecated(k, where, obj, [key, value]);
          if (this.definitions[key]?.exclusive) {
            for (const exclusive of this.definitions[key].exclusive) {
              if (!this.isDefault(exclusive)) {
                throw new TypeError(`--${key} can not be provided when using --${exclusive}`)
              }
            }
          }
        }
        conf.data[k] = v;
      }
    }
  }

  #checkDeprecated (key, where, obj, kv) {
    // XXX(npm9+) make this throw an error
    if (this.deprecated[key]) {
      log.warn('config', key, this.deprecated[key]);
    }
  }

  // Parse a field, coercing it to the best type available.
  parseField (f, key, listElement = false) {
    return parseField(f, key, this, listElement)
  }

  async #loadFile (file, type) {
    // only catch the error from readFile, not from the loadObject call
    log.silly(`config:load:file:${file}`);
    await readFile(file, 'utf8').then(
      data => {
        const parsedConfig = ini.parse(data);
        if (type === 'project' && parsedConfig.prefix) {
          // Log error if prefix is mentioned in project .npmrc
          /* eslint-disable-next-line max-len */
          log.error('config', `prefix cannot be changed from project config: ${file}.`);
        }
        return this.#loadObject(parsedConfig, type, file)
      },
      er => this.#loadObject(null, type, file, er)
    );
  }

  loadBuiltinConfig () {
    return this.#loadFile(resolve(this.npmPath, 'npmrc'), 'builtin')
  }

  async loadProjectConfig () {
    // the localPrefix can be set by the CLI config, but otherwise is
    // found by walking up the folder tree. either way, we load it before
    // we return to make sure localPrefix is set
    await this.loadLocalPrefix();

    // if we have not detected a local package json yet, try now that we
    // have a local prefix
    if (this.localPackage == null) {
      this.localPackage = await fileExists(this.localPrefix, 'package.json');
    }

    if (this.#get('global') === true || this.#get('location') === 'global') {
      this.data.get('project').source = '(global mode enabled, ignored)';
      this.sources.set(this.data.get('project').source, 'project');
      return
    }

    const projectFile = resolve(this.localPrefix, '.npmrc');
    // if we're in the ~ directory, and there happens to be a node_modules
    // folder (which is not TOO uncommon, it turns out), then we can end
    // up loading the "project" config where the "userconfig" will be,
    // which causes some calamaties.  So, we only load project config if
    // it doesn't match what the userconfig will be.
    if (projectFile !== this.#get('userconfig')) {
      return this.#loadFile(projectFile, 'project')
    } else {
      this.data.get('project').source = '(same as "user" config, ignored)';
      this.sources.set(this.data.get('project').source, 'project');
    }
  }

  async loadLocalPrefix () {
    const cliPrefix = this.#get('prefix', 'cli');
    if (cliPrefix) {
      this.localPrefix = cliPrefix;
      return
    }

    const cliWorkspaces = this.#get('workspaces', 'cli');
    const isGlobal = this.#get('global') || this.#get('location') === 'global';

    for (const p of walkUp(this.cwd)) {
      // HACK: this is an option set in tests to stop the local prefix from being set
      // on tests that are created inside the npm repo
      if (this.excludeNpmCwd && p === this.npmPath) {
        break
      }

      const hasPackageJson = await fileExists(p, 'package.json');

      if (!this.localPrefix && (hasPackageJson || await dirExists(p, 'node_modules'))) {
        this.localPrefix = p;
        this.localPackage = hasPackageJson;

        // if workspaces are disabled, or we're in global mode, return now
        if (cliWorkspaces === false || isGlobal) {
          return
        }

        // otherwise, continue the loop
        continue
      }

      if (this.localPrefix && hasPackageJson) {
        const rpj = requireLib$2();
        // if we already set localPrefix but this dir has a package.json
        // then we need to see if `p` is a workspace root by reading its package.json
        // however, if reading it fails then we should just move on
        const pkg = await rpj(resolve(p, 'package.json')).catch(() => false);
        if (!pkg) {
          continue
        }

        const mapWorkspaces = requireLib();
        const workspaces = await mapWorkspaces({ cwd: p, pkg });
        for (const w of workspaces.values()) {
          if (w === this.localPrefix) {
            // see if there's a .npmrc file in the workspace, if so log a warning
            if (await fileExists(this.localPrefix, '.npmrc')) {
              log.warn(`ignoring workspace config at ${this.localPrefix}/.npmrc`);
            }

            // set the workspace in the default layer, which allows it to be overridden easily
            const { data } = this.data.get('default');
            data.workspace = [this.localPrefix];
            this.localPrefix = p;
            this.localPackage = hasPackageJson;
            log.info(`found workspace root at ${this.localPrefix}`);
            // we found a root, so we return now
            return
          }
        }
      }
    }

    if (!this.localPrefix) {
      this.localPrefix = this.cwd;
    }
  }

  loadUserConfig () {
    return this.#loadFile(this.#get('userconfig'), 'user')
  }

  loadGlobalConfig () {
    return this.#loadFile(this.#get('globalconfig'), 'global')
  }

  async save (where) {
    if (!this.loaded) {
      throw new Error('call config.load() before saving')
    }
    if (!confFileTypes.has(where)) {
      throw new Error('invalid config location param: ' + where)
    }

    const conf = this.data.get(where);
    conf[_loadError] = null;

    if (where === 'user') {
      // if email is nerfed, then we want to de-nerf it
      const nerfed = nerfDart(this.get('registry'));
      const email = this.get(`${nerfed}:email`, 'user');
      if (email) {
        this.delete(`${nerfed}:email`, 'user');
        this.set('email', email, 'user');
      }
    }

    // We need the actual raw data before we called parseField so that we are
    // saving the same content back to the file
    const iniData = ini.stringify(conf.raw).trim() + '\n';
    if (!iniData.trim()) {
      // ignore the unlink error (eg, if file doesn't exist)
      await unlink(conf.source).catch(er => {});
      return
    }
    const dir = dirname(conf.source);
    await mkdir(dir, { recursive: true });
    await writeFile(conf.source, iniData, 'utf8');
    const mode = where === 'user' ? 0o600 : 0o666;
    await chmod(conf.source, mode);
  }

  clearCredentialsByURI (uri, level = 'user') {
    const nerfed = nerfDart(uri);
    const def = nerfDart(this.get('registry'));
    if (def === nerfed) {
      this.delete(`-authtoken`, level);
      this.delete(`_authToken`, level);
      this.delete(`_authtoken`, level);
      this.delete(`_auth`, level);
      this.delete(`_password`, level);
      this.delete(`username`, level);
      // de-nerf email if it's nerfed to the default registry
      const email = this.get(`${nerfed}:email`, level);
      if (email) {
        this.set('email', email, level);
      }
    }
    this.delete(`${nerfed}:_authToken`, level);
    this.delete(`${nerfed}:_auth`, level);
    this.delete(`${nerfed}:_password`, level);
    this.delete(`${nerfed}:username`, level);
    this.delete(`${nerfed}:email`, level);
    this.delete(`${nerfed}:certfile`, level);
    this.delete(`${nerfed}:keyfile`, level);
  }

  setCredentialsByURI (uri, { token, username, password, email, certfile, keyfile }) {
    const nerfed = nerfDart(uri);

    // email is either provided, a top level key, or nothing
    email = email || this.get('email', 'user');

    // field that hasn't been used as documented for a LONG time,
    // and as of npm 7.10.0, isn't used at all.  We just always
    // send auth if we have it, only to the URIs under the nerf dart.
    this.delete(`${nerfed}:always-auth`, 'user');

    this.delete(`${nerfed}:email`, 'user');
    if (certfile && keyfile) {
      this.set(`${nerfed}:certfile`, certfile, 'user');
      this.set(`${nerfed}:keyfile`, keyfile, 'user');
      // cert/key may be used in conjunction with other credentials, thus no `else`
    }
    if (token) {
      this.set(`${nerfed}:_authToken`, token, 'user');
      this.delete(`${nerfed}:_password`, 'user');
      this.delete(`${nerfed}:username`, 'user');
    } else if (username || password) {
      if (!username) {
        throw new Error('must include username')
      }
      if (!password) {
        throw new Error('must include password')
      }
      this.delete(`${nerfed}:_authToken`, 'user');
      this.set(`${nerfed}:username`, username, 'user');
      // note: not encrypted, no idea why we bothered to do this, but oh well
      // protects against shoulder-hacks if password is memorable, I guess?
      const encoded = Buffer.from(password, 'utf8').toString('base64');
      this.set(`${nerfed}:_password`, encoded, 'user');
    } else if (!certfile || !keyfile) {
      throw new Error('No credentials to set.')
    }
  }

  // this has to be a bit more complicated to support legacy data of all forms
  getCredentialsByURI (uri) {
    const nerfed = nerfDart(uri);
    const def = nerfDart(this.get('registry'));
    const creds = {};

    // email is handled differently, it used to always be nerfed and now it never should be
    // if it's set nerfed to the default registry, then we copy it to the unnerfed key
    // TODO: evaluate removing 'email' from the credentials object returned here
    const email = this.get(`${nerfed}:email`) || this.get('email');
    if (email) {
      if (nerfed === def) {
        this.set('email', email, 'user');
      }
      creds.email = email;
    }

    const certfileReg = this.get(`${nerfed}:certfile`);
    const keyfileReg = this.get(`${nerfed}:keyfile`);
    if (certfileReg && keyfileReg) {
      creds.certfile = certfileReg;
      creds.keyfile = keyfileReg;
      // cert/key may be used in conjunction with other credentials, thus no `return`
    }

    const tokenReg = this.get(`${nerfed}:_authToken`);
    if (tokenReg) {
      creds.token = tokenReg;
      return creds
    }

    const userReg = this.get(`${nerfed}:username`);
    const passReg = this.get(`${nerfed}:_password`);
    if (userReg && passReg) {
      creds.username = userReg;
      creds.password = Buffer.from(passReg, 'base64').toString('utf8');
      const auth = `${creds.username}:${creds.password}`;
      creds.auth = Buffer.from(auth, 'utf8').toString('base64');
      return creds
    }

    const authReg = this.get(`${nerfed}:_auth`);
    if (authReg) {
      const authDecode = Buffer.from(authReg, 'base64').toString('utf8');
      const authSplit = authDecode.split(':');
      creds.username = authSplit.shift();
      creds.password = authSplit.join(':');
      creds.auth = authReg;
      return creds
    }

    // at this point, nothing else is usable so just return what we do have
    return creds
  }

  // set up the environment object we have with npm_config_* environs
  // for all configs that are different from their default values, and
  // set EDITOR and HOME.
  setEnvs () {
    setEnvs(this);
  }
}

const _loadError = Symbol('loadError');
const _valid = Symbol('valid');

class ConfigData {
  #data
  #source = null
  #raw = null
  constructor (parent) {
    this.#data = Object.create(parent && parent.data);
    this.#raw = {};
    this[_valid] = true;
  }

  get data () {
    return this.#data
  }

  get valid () {
    return this[_valid]
  }

  set source (s) {
    if (this.#source) {
      throw new Error('cannot set ConfigData source more than once')
    }
    this.#source = s;
  }

  get source () {
    return this.#source
  }

  set loadError (e) {
    if (this[_loadError] || (Object.keys(this.#raw).length)) {
      throw new Error('cannot set ConfigData loadError after load')
    }
    this[_loadError] = e;
  }

  get loadError () {
    return this[_loadError]
  }

  set raw (r) {
    if (Object.keys(this.#raw).length || this[_loadError]) {
      throw new Error('cannot set ConfigData raw after load')
    }
    this.#raw = r;
  }

  get raw () {
    return this.#raw
  }
}

var lib = Config;

const index = /*@__PURE__*/getDefaultExportFromCjs(lib);

const index$1 = {
	__proto__: null,
	default: index
};

export { index$1 as i };
